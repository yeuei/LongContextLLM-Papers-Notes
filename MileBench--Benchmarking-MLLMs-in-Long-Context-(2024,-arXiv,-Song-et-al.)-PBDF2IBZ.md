---
tags: []
parent: 'MileBench: Benchmarking MLLMs in Long Context'
collections:
    - 'Long context LLM'
$version: 5941
$libraryID: 1
$itemKey: PBDF2IBZ

---
# MileBench: Benchmarking MLLMs in Long Context (2024, arXiv, Song et al.)

***

| <!-- --> |
| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **<span style="color: rgb(60, 90, 204)"><span style="background-color: rgb(246, 248, 250)">Author: </span></span>**<span style="background-color: rgb(246, 248, 250)">Dingjie Song; Shunian Chen; Guiming Hardy Chen; Fei Yu; Xiang Wan; Benyou Wang</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| **<span style="color: rgb(60, 90, 204)"><span style="background-color: rgb(236, 243, 250)">Source: </span></span>**<span style="background-color: rgb(236, 243, 250)">arXiv</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| **<span style="color: rgb(60, 90, 204)"><span style="background-color: rgb(246, 248, 250)">DOI: </span></span>**<span style="background-color: rgb(246, 248, 250)"><a href="https://doi.org/10.48550/arXiv.2404.18532" rel="noopener noreferrer nofollow">10.48550/arXiv.2404.18532</a></span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| **<span style="color: rgb(60, 90, 204)"><span style="background-color: rgb(236, 243, 250)">Date: </span></span>**<span style="background-color: rgb(236, 243, 250)">2024-05-15</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| **<span style="color: rgb(60, 90, 204)"><span style="background-color: rgb(246, 248, 250)">Full Text: </span></span>**<span style="background-color: rgb(246, 248, 250)"><a href="zotero://open-pdf/0_DGHN9QHG" rel="noopener noreferrer nofollow">Song ç­‰ - 2024 - MileBench Benchmarking MLLMs in Long Context.pdf</a></span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| **<span style="color: rgb(60, 90, 204)"><span style="background-color: rgb(236, 243, 250)">Abstract: </span></span>***<span style="background-color: rgb(236, 243, 250)">Despite the advancements and impressive performance of Multimodal Large Language Models (MLLMs) on benchmarks, their effectiveness in real-world, long-context, and multi-image tasks is unclear due to the benchmarks' limited scope. Existing benchmarks often focus on single-image and short-text samples, and when assessing multi-image tasks, they either limit the image count or focus on specific task (e.g time-series captioning), potentially obscuring the performance challenges of MLLMs. To address these limitations, we introduce MileBench, a pioneering benchmark designed to test the MultImodal Long-contExt capabilities of MLLMs. This benchmark comprises not only multimodal long contexts, but also multiple tasks requiring both comprehension and generation. We establish two distinct evaluation sets, diagnostic and realistic, to systematically assess MLLMs' long-context adaptation capacity and their ability to complete tasks in long-context scenarios. Our experimental results, obtained from testing 22 models, revealed that while the closed-source GPT-4o outperforms others, most open-source MLLMs struggle in long-context situations. Interestingly, the performance gap tends to widen with an increase in the number of images. We strongly encourage an intensification of research efforts towards enhancing MLLMs' long-context capabilities, especially in scenarios involving multiple images.</span>* |


***

## <span style="color: rgb(190, 27, 65)">ğŸŒèƒŒæ™¯&#x26;ç›®å‰çš„æŒ‘æˆ˜ï¼š</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22INT49RGG%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B245.626%2C251.962%2C468.13%2C261.546%5D%2C%5B143.865%2C241.003%2C468.33%2C250.587%5D%2C%5B143.865%2C230.044%2C345.09%2C239.628%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=1&#x26;annotation=INT49RGG"><span style="background-color: #ff666680">â€œExisting benchmarks often focus on single-image and short-text samples, and when assessing multi-image tasks, they either limit the image count or focus on specific taskâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 1</a></span>)</span>\
**ç°æœ‰çš„åŸºå‡†é€šå¸¸å…³æ³¨å•å¼ å›¾åƒå’ŒçŸ­æ–‡æœ¬æ ·æœ¬ï¼Œè€Œåœ¨è¯„ä¼°å¤šå›¾åƒä»»åŠ¡æ—¶ï¼Œå®ƒä»¬è¦ä¹ˆé™åˆ¶å›¾åƒæ•°é‡ï¼Œè¦ä¹ˆä¸“æ³¨äºç‰¹å®šä»»åŠ¡ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%228H3SFK8Y%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B166.662%2C334.012%2C505.651%2C343.596%5D%2C%5B107.691%2C323.053%2C504.004%2C332.637%5D%2C%5B108%2C312.094%2C503.998%2C321.678%5D%2C%5B108%2C301.135%2C504.001%2C310.719%5D%2C%5B107.671%2C290.176%2C503.995%2C299.76%5D%2C%5B108%2C279.217%2C447.944%2C288.801%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=2&#x26;annotation=8H3SFK8Y"><span style="background-color: #ff666680">â€œexisting benchmarks primarily focus on single-image and short-text samples (Liu et al., 2023a; Fu et al., 2023; Liu et al., 2023c; Li et al., 2023b), thereby failing to fully capture the complexity and diversity of real-world scenarios. While some benchmarks evaluate multi-image tasks, they either have limited number of images provided per sample (e.g., SEED-Bench-2 (Li et al., 2023a), DEMON (Li et al., 2023c)) or only include time-series captioning tasks (e.g., Mementos (Wang et al., 2024)), as shown in Figure 2.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 2</a></span>)</span>\
**ç°æœ‰çš„åŸºå‡†æµ‹è¯•ä¸»è¦å…³æ³¨å•å›¾åƒå’ŒçŸ­æ–‡æœ¬æ ·æœ¬ï¼ˆLiuç­‰ï¼Œ2023aï¼›Fuç­‰ï¼Œ2023ï¼›Liuç­‰ï¼Œ2023cï¼›Liç­‰ï¼Œ2023bï¼‰ï¼Œå› æ­¤æœªèƒ½å……åˆ†æ•æ‰çœŸå®ä¸–ç•Œåœºæ™¯çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ã€‚å°½ç®¡æŸäº›åŸºå‡†æµ‹è¯•è¯„ä¼°å¤šå›¾åƒä»»åŠ¡ï¼Œä½†å®ƒä»¬æä¾›çš„æ¯ä¸ªæ ·æœ¬çš„å›¾åƒæ•°é‡æœ‰é™ï¼ˆä¾‹å¦‚ï¼ŒSEED-Bench-2ï¼ˆLiç­‰ï¼Œ2023aï¼‰ï¼ŒDEMONï¼ˆLiç­‰ï¼Œ2023cï¼‰ï¼‰ï¼Œæˆ–è€…ä»…åŒ…æ‹¬æ—¶é—´åºåˆ—æè¿°ä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼ŒMementosï¼ˆWangç­‰ï¼Œ2024ï¼‰ï¼‰ï¼Œå¦‚å›¾2æ‰€ç¤ºã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22J3FF2JAQ%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B452.273%2C279.217%2C505.247%2C288.801%5D%2C%5B108%2C268.258%2C503.998%2C277.842%5D%2C%5B108%2C257.299%2C316.918%2C266.883%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=2&#x26;annotation=J3FF2JAQ"><span style="background-color: #ff666680">â€œIn addition, this omission could potentially neglect the hallucination issue that MLLMs might exhibit in long-context situations (Huang et al., 2023).â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 2</a></span>)</span>\
**æ­¤å¤–ï¼Œè¿™ä¸€é—æ¼å¯èƒ½ä¼šå¿½è§†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸­å¯èƒ½è¡¨ç°å‡ºçš„å¹»è§‰é—®é¢˜ï¼ˆHuang ç­‰, 2023ï¼‰ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22TE3HKTY7%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B205.918%2C235.381%2C503.997%2C244.965%5D%2C%5B108%2C224.422%2C164.259%2C234.006%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=2&#x26;annotation=TE3HKTY7"><span style="background-color: #ff666680">â€œlong-context and multi-image task demands prevalent in real-world applications.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 2</a></span>)</span>\
**ç°å®ä¸–ç•Œåº”ç”¨ä¸­æ™®éå­˜åœ¨çš„é•¿ä¸Šä¸‹æ–‡å’Œå¤šå›¾åƒä»»åŠ¡éœ€æ±‚ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22MQYE5HL7%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B108%2C562.216%2C505.654%2C571.8%5D%2C%5B108%2C551.257%2C429.257%2C560.841%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=3&#x26;annotation=MQYE5HL7"><span style="background-color: #ff666680">â€œBeyond training on single-image-text pairs, recent developments in MLLMs are also oriented towards handling multiple and interleaved image-text sequencesâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 3</a></span>)</span>\
**é™¤åŸºäºå•å›¾åƒ-æ–‡æœ¬å¯¹çš„è®­ç»ƒå¤–ï¼Œæœ€è¿‘å…³äºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„ç ”ç©¶ä¹Ÿå€¾å‘äºå¤„ç†å¤šå›¾åƒ-æ–‡æœ¬åºåˆ—ä»¥åŠäº¤é”™å›¾åƒ-æ–‡æœ¬åºåˆ—ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%226FJ9694D%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B339.452%2C507.421%2C504.294%2C517.005%5D%2C%5B108%2C496.462%2C390.961%2C506.046%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=3&#x26;annotation=6FJ9694D"><span style="background-color: #ff666680">â€œHowever, there remains a notable gap in open-source MLLMs capable of long-context comprehension.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 3</a></span>)</span>\
**ç„¶è€Œï¼Œå¼€æºçš„èƒ½å¤Ÿç†è§£é•¿ä¸Šä¸‹æ–‡çš„å¤šè¯­è¨€å¤§æ¨¡å‹ï¼ˆMLLMsï¼‰ä»ç„¶å­˜åœ¨æ˜¾è‘—çš„ç©ºç™½ã€‚**

## <span style="color: rgb(190, 27, 65)">ğŸ”¬è®ºæ–‡æå‡ºçš„æ–¹æ³•ï¼š</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22NH7KP26Z%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B282.66%2C208.126%2C469.789%2C217.71%5D%2C%5B143.865%2C197.167%2C445.702%2C206.751%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=1&#x26;annotation=NH7KP26Z"><span style="background-color: #5fb23680">â€œMILEBENCH, a pioneering benchmark designed to test the MultImodal Long-contExt capabilities of MLLMs.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 1</a></span>)</span>\
**MILEBENCHï¼Œä¸€ä¸ªæ—¨åœ¨æµ‹è¯•å¤šæ¨¡æ€é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›çš„å¼€åˆ›æ€§åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs)ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22B8EU6KEQ%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B390.229%2C175.249%2C468.13%2C184.833%5D%2C%5B143.865%2C164.29%2C468.13%2C173.874%5D%2C%5B143.865%2C153.331%2C468.13%2C162.915%5D%2C%5B143.865%2C142.372%2C283.438%2C151.956%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=1&#x26;annotation=B8EU6KEQ"><span style="background-color: #5fb23680">â€œWe establish two distinct evaluation sets, diagnostic and realistic, to systematically assess MLLMsâ€™ long-context adaptation capacity and their ability to complete tasks in long-context scenarios.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 1</a></span>)</span>\
**æˆ‘ä»¬å»ºç«‹äº†ä¸¤ä¸ªä¸åŒçš„è¯„ä¼°é›†ï¼šè¯Šæ–­é›†å’Œç°å®é›†ï¼Œä»¥ç³»ç»Ÿåœ°è¯„ä¼°MLLMsåœ¨é•¿ä¸Šä¸‹æ–‡é€‚åº”èƒ½åŠ›ä»¥åŠå…¶åœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯å®Œæˆä»»åŠ¡çš„èƒ½åŠ›ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%222N3KXP7S%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B180.148%2C172.861%2C504.002%2C182.445%5D%2C%5B108%2C161.902%2C503.997%2C171.486%5D%2C%5B108%2C150.943%2C503.997%2C160.527%5D%2C%5B108%2C139.984%2C428.382%2C149.568%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=2&#x26;annotation=2N3KXP7S"><span style="background-color: #5fb23680">â€œdiagnostic evaluation and realistic evaluation. The former explores the long-context recall abilities of MLLMs, using needle-in-a-haystack and image retrieval tasks, while the latter stress-tests the model in a manner akin to real-world conditions using both temporal multi-image tasks and semantic multi-image tasks.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 2</a></span>)</span>\
**è¯Šæ–­è¯„ä¼°å’Œç°å®è¯„ä¼°ã€‚å‰è€…é€šè¿‡â€œå¤§æµ·æé’ˆâ€å’Œå›¾åƒæ£€ç´¢ä»»åŠ¡æ¥æ¢ç´¢å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„é•¿æ—¶è®°å¿†å›æº¯èƒ½åŠ›ï¼Œè€Œåè€…é€šè¿‡æ—¶é—´æ€§å¤šå›¾åƒä»»åŠ¡å’Œè¯­ä¹‰æ€§å¤šå›¾åƒä»»åŠ¡ï¼Œä»¥ç±»ä¼¼çœŸå®ä¸–ç•Œçš„æ¡ä»¶å¯¹æ¨¡å‹è¿›è¡Œå‹åŠ›æµ‹è¯•ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22BZJTJJYM%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B180.057%2C318.224%2C503.999%2C327.808%5D%2C%5B108%2C307.265%2C503.997%2C316.849%5D%2C%5B108%2C296.306%2C186.376%2C305.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=3&#x26;annotation=BZJTJJYM"><span style="background-color: #5fb23680">â€œMILEBENCH is the first comprehensive benchmark that evaluates MLLMs across both multi-image and long-context dimensions, catering to a broader spectrum of general scenarios.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 3</a></span>)</span>\
**MILEBENCH æ˜¯é¦–ä¸ªç»¼åˆæ€§åŸºå‡†ï¼Œèƒ½å¤Ÿè·¨å¤šå›¾åƒå’Œé•¿ä¸Šä¸‹æ–‡ç»´åº¦è¯„ä¼° MLLMï¼Œé€‚ç”¨äºæ›´å¹¿æ³›çš„é€šç”¨åœºæ™¯ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22PNGQ3TVT%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B107.502%2C196.907%2C504.004%2C206.491%5D%2C%5B108%2C185.948%2C326.948%2C195.532%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%226%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=6&#x26;annotation=PNGQ3TVT"><span style="background-color: #5fb23680">â€œWe have established a robust data collection process and meticulous review procedures to maintain the integrity and quality of our datasets.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 6</a></span>)</span>\
**æˆ‘ä»¬å·²å»ºç«‹äº†å®Œå–„çš„æ•°æ®æ”¶é›†æµç¨‹å’Œä¸¥è°¨çš„å®¡æŸ¥ç¨‹åºï¼Œä»¥ç»´æŠ¤æ•°æ®é›†çš„å®Œæ•´æ€§å’Œè´¨é‡ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%228MBFWVTL%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B488.984%2C321.302%2C504.196%2C330.886%5D%2C%5B108%2C310.343%2C503.996%2C319.927%5D%2C%5B108%2C299.384%2C429.971%2C308.968%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%227%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=7&#x26;annotation=8MBFWVTL"><span style="background-color: #5fb23680">â€œFor open-ended generation tasks, the popular n-gram-based metric ROUGE-L is adopted, and accuracy is the metric for multiple-choice and needle-in-a-haystack tasks.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 7</a></span>)</span>\
**å¯¹äºå¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡ï¼Œé‡‡ç”¨æµè¡Œçš„åŸºäºnå…ƒæ¨¡å‹çš„æŒ‡æ ‡ROUGE-Lï¼Œè€Œå¯¹äºå¤šé¡¹é€‰æ‹©é¢˜å’Œå¤§æµ·æé’ˆä»»åŠ¡ï¼Œåˆ™ä½¿ç”¨å‡†ç¡®ç‡ä½œä¸ºæŒ‡æ ‡ã€‚**

## <span style="color: rgb(190, 27, 65)">ğŸ“œè®ºæ–‡çš„ç»“è®ºï¼š</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22VVB5QZJM%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B143.865%2C109.496%2C468.139%2C119.08%5D%2C%5B143.865%2C98.537%2C468.13%2C108.121%5D%2C%5B143.865%2C87.578%2C468.135%2C97.162%5D%2C%5B143.865%2C76.619%2C305.777%2C86.203%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=1&#x26;annotation=VVB5QZJM"><span style="background-color: #2ea8e580">â€œInterestingly, the performance gap tends to widen with an increase in the number of images. We strongly encourage an intensification of research efforts towards enhancing MLLMsâ€™ long-context capabilities, especially in scenarios involving multiple images.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 1</a></span>)</span>\
**éšç€å›¾åƒæ•°é‡çš„å¢åŠ ï¼Œæ€§èƒ½å·®è·å¾€å¾€ä¼šæ‰©å¤§ã€‚æˆ‘ä»¬å¼ºçƒˆå»ºè®®åŠ å¤§ç ”ç©¶åŠ›åº¦ï¼Œç€é‡æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å¤„ç†é•¿ä¸Šä¸‹æ–‡çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠå¤šå¼ å›¾åƒçš„åœºæ™¯ä¸­ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22BAB4R9TH%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B107.502%2C239.175%2C505.241%2C248.759%5D%2C%5B107.671%2C228.216%2C503.999%2C237.8%5D%2C%5B108%2C217.257%2C503.997%2C226.841%5D%2C%5B108%2C206.298%2C503.997%2C215.882%5D%2C%5B108%2C195.339%2C333.935%2C204.923%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%227%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=7&#x26;annotation=BAB4R9TH"><span style="background-color: #2ea8e580">â€œWe present the results of our experiments in Table 2 and summarize our findings as follows: (1) Closed-source MLLMs outperform open-source MLLMs in multimodal long-context tasks to date, particularly in diagnostic evaluation of long-context adaptability where the gap between closed-source MLLMs (average: 79.2%, max: 99.4%) and open-source MLLMs (average: 10.1%, max: 37.2%) is significant.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 7</a></span>)</span>\
**(1) é—­æºçš„å¤šæ¨¡æ€é•¿æ–‡æœ¬æ¨¡å‹ (MLLMs)åœ¨å¤šæ¨¡æ€é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸­ä¼˜äºå¼€æºçš„å¤šæ¨¡æ€é•¿æ–‡æœ¬æ¨¡å‹(MLLMs),ç‰¹åˆ«æ˜¯åœ¨ é•¿ä¸Šä¸‹æ–‡é€‚åº”æ€§çš„è¯Šæ–­è¯„ä¼°ä¸­,é—­æºçš„å¤šæ¨¡æ€é•¿æ–‡æœ¬æ¨¡å‹(å¹³å‡:79.2%,æœ€é«˜:99.4%)ä¸ å¼€æºçš„å¤šæ¨¡æ€é•¿æ–‡æœ¬æ¨¡å‹(å¹³å‡:10.1%,æœ€é«˜:37.2%)ä¹‹é—´çš„å·®è·æ˜¾è‘—ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22Q327BGMF%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B398.162%2C184.38%2C504.002%2C193.964%5D%2C%5B108%2C173.422%2C410.518%2C183.006%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%227%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=7&#x26;annotation=Q327BGMF"><span style="background-color: #2ea8e580">â€œ(2) Open-source image models generally perform better than open-source video models.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 7</a></span>)</span>\
**å¼€æºå›¾åƒæ¨¡å‹é€šå¸¸æ¯”å¼€æºè§†é¢‘æ¨¡å‹è¡¨ç°æ›´å¥½ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22K5ZWW27P%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B402.657%2C422.276%2C504.004%2C431.86%5D%2C%5B108%2C411.317%2C505.245%2C420.901%5D%2C%5B107.582%2C400.359%2C505.243%2C409.943%5D%2C%5B108%2C389.4%2C504.001%2C399.013%5D%2C%5B108%2C378.441%2C259.792%2C388.025%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%228%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=8&#x26;annotation=K5ZWW27P"><span style="background-color: #2ea8e580">â€œThe ability to adapt to long contexts and perform long-context tasks are not necessarily linked. For example, while Qwen-VL-Chat scores the highest in diagnostic evaluation among open-source models, it trails behind Mantis in task completion (39.1% &#x3C;47.5%), highlighting our evaluationâ€™s diversity and comprehensiveness.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%228%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 8</a></span>)</span>\
**é€‚åº”é•¿ä¸Šä¸‹æ–‡çš„èƒ½åŠ›ä¸æ‰§è¡Œé•¿ä¸Šä¸‹æ–‡ä»»åŠ¡çš„èƒ½åŠ›å¹¶ä¸ä¸€å®šç›¸å…³ã€‚ä¾‹å¦‚ï¼Œå°½ç®¡Qwen-VL-Chatåœ¨å¼€æºæ¨¡å‹ä¸­è¯Šæ–­è¯„ä¼°å¾—åˆ†æœ€é«˜ï¼Œä½†åœ¨ä»»åŠ¡å®Œæˆç‡ä¸Šå´è½åäºMantisï¼ˆ39.1% <47.5%ï¼‰ï¼Œè¿™çªæ˜¾äº†æˆ‘ä»¬è¯„ä¼°çš„å¤šæ ·æ€§å’Œå…¨é¢æ€§ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22E64M37FK%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B277.133%2C378.441%2C503.997%2C388.025%5D%2C%5B108%2C367.482%2C337.029%2C377.066%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%228%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=8&#x26;annotation=E64M37FK"><span style="background-color: #2ea8e580">â€œInterestingly, the majority of open-source models scored zero in the Image Needle in a Haystack task.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%228%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 8</a></span>)</span>\
**æœ‰è¶£çš„æ˜¯ï¼Œå¤§å¤šæ•°å¼€æºæ¨¡å‹åœ¨â€œå›¾åƒå¤§æµ·æé’ˆâ€ä»»åŠ¡ä¸­å¾—åˆ†ä¸ºé›¶ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%229Y6X6DPA%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%229%22%2C%22position%22%3A%7B%22pageIndex%22%3A8%2C%22rects%22%3A%5B%5B108%2C321.531%2C329.376%2C330.876%5D%2C%5B108%2C310.413%2C312.436%2C319.997%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%229%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=9&#x26;annotation=9Y6X6DPA"><span style="background-color: #2ea8e580">â€œas the number of images increases, the performance of most models significantly declinesâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 9</a></span>)</span>\
**éšç€å›¾åƒæ•°é‡çš„å¢åŠ ï¼Œå¤§å¤šæ•°æ¨¡å‹çš„æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%224KKWCUGD%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%229%22%2C%22position%22%3A%7B%22pageIndex%22%3A8%2C%22rects%22%3A%5B%5B232.493%2C255.618%2C329.376%2C265.202%5D%2C%5B108%2C244.659%2C327.72%2C254.243%5D%2C%5B108%2C233.7%2C327.72%2C243.284%5D%2C%5B108%2C222.741%2C329.376%2C232.325%5D%2C%5B108%2C211.783%2C504.001%2C221.367%5D%2C%5B108%2C200.824%2C465.392%2C210.408%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%229%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=9&#x26;annotation=4KKWCUGD"><span style="background-color: #2ea8e580">â€œHowever, the performance of GPT-4V, GPT-4o, Gemini 1.5, Claude 3 Opus and Qwen-VL-Chat on the Medium level surpasses that of the Few level. This could be attributed to their training on multi-image data, where a larger number of images can provide more information to some extent, thereby aiding the model in task completion.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 9</a></span>)</span>\
**ç„¶è€Œï¼ŒGPT-4Vã€GPT-4oã€Gemini 1.5ã€Claude 3 Opus å’Œ Qwen-VL-Chat åœ¨ä¸­ç­‰æ°´å¹³ä¸Šçš„è¡¨ç°è¶…è¿‡äº†åœ¨å°‘é‡æ°´å¹³ä¸Šçš„è¡¨ç°ã€‚è¿™å¯èƒ½å½’å› äºå®ƒä»¬åœ¨å¤šå›¾åƒæ•°æ®ä¸Šçš„è®­ç»ƒï¼Œå…¶ä¸­è¾ƒå¤šçš„å›¾åƒåœ¨æŸç§ç¨‹åº¦ä¸Šå¯ä»¥æä¾›æ›´å¤šçš„ä¿¡æ¯ï¼Œä»è€Œå¸®åŠ©æ¨¡å‹å®Œæˆä»»åŠ¡ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22E4CWXFTA%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%229%22%2C%22position%22%3A%7B%22pageIndex%22%3A8%2C%22rects%22%3A%5B%5B297.498%2C59.329%2C483.226%2C68.913%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%229%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=9&#x26;annotation=E4CWXFTA"><span style="background-color: #2ea8e580">â€œGPT-4V did not â€œget lost in the middleâ€â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 9</a></span>)</span>\
**GPT-4V å¹¶æ²¡æœ‰â€œåœ¨ä¸­é€”è¿·å¤±â€ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22MWP7ZY5F%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%2210%22%2C%22position%22%3A%7B%22pageIndex%22%3A9%2C%22rects%22%3A%5B%5B139.356%2C419.378%2C504.004%2C428.962%5D%2C%5B108%2C408.419%2C503.997%2C418.003%5D%2C%5B108%2C397.46%2C481.529%2C407.044%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2210%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=10&#x26;annotation=MWP7ZY5F"><span style="background-color: #2ea8e580">â€œOn the other hand, ignoring the scenarios where the data exceeds its maximum context length (8192 tokens or 32 images) and gets truncated, Qwen-VL-Chat showed a certain degree of â€œlost in the middleâ€, particularly evident in the image needle task.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2210%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 10</a></span>)</span>\
**å¦ä¸€æ–¹é¢ï¼Œå¿½ç•¥æ•°æ®è¶…è¿‡æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆ8192ä¸ªæ ‡è®°æˆ–32å¼ å›¾ç‰‡ï¼‰å¹¶è¢«æˆªæ–­çš„æƒ…å†µï¼ŒQwen-VL-Chatæ˜¾ç¤ºå‡ºä¸€å®šç¨‹åº¦çš„â€œä¸­é€”ä¸¢å¤±â€ï¼Œè¿™ä¸€ç°è±¡åœ¨å›¾åƒé’ˆä»»åŠ¡ä¸­å°¤å…¶æ˜æ˜¾ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22A3AUAXDD%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%2210%22%2C%22position%22%3A%7B%22pageIndex%22%3A9%2C%22rects%22%3A%5B%5B484.615%2C397.46%2C504.005%2C407.044%5D%2C%5B108%2C386.501%2C505.744%2C396.085%5D%2C%5B108%2C375.542%2C471.605%2C385.126%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2210%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=10&#x26;annotation=A3AUAXDD"><span style="background-color: #2ea8e580">â€œThis indicates that the â€œlost in the middleâ€ phenomenon also exists in multimodal scenarios. However, a strong ability to manage long context can significantly reduce this risk.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2210%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 10</a></span>)</span>\
**è¿™è¡¨æ˜â€œä¸­é—´è¿·å¤±â€ç°è±¡ä¹Ÿå­˜åœ¨äºå¤šæ¨¡æ€åœºæ™¯ä¸­ã€‚ç„¶è€Œï¼Œå¼ºå¤§çš„é•¿ä¸Šä¸‹æ–‡ç®¡ç†èƒ½åŠ›å¯ä»¥æ˜¾è‘—é™ä½è¿™ä¸€é£é™©ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22FZNB9RN7%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%2210%22%2C%22position%22%3A%7B%22pageIndex%22%3A9%2C%22rects%22%3A%5B%5B108%2C330.013%2C296.035%2C339.597%5D%2C%5B108%2C319.055%2C296.037%2C328.639%5D%2C%5B108%2C308.096%2C175.318%2C317.68%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2210%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=10&#x26;annotation=FZNB9RN7"><span style="background-color: #2ea8e580">â€œConsidering MILEBENCHâ€™s use of public datasets, thereâ€™s a potential risk of data contamination.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2210%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 10</a></span>)</span>\
**è€ƒè™‘åˆ°MILEBENCHä½¿ç”¨å…¬å…±æ•°æ®é›†ï¼Œå­˜åœ¨æ•°æ®æ±¡æŸ“çš„æ½œåœ¨é£é™©ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22S2U2ZZL4%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%2210%22%2C%22position%22%3A%7B%22pageIndex%22%3A9%2C%22rects%22%3A%5B%5B230.711%2C253.301%2C296.041%2C262.885%5D%2C%5B107.502%2C242.342%2C297.69%2C251.926%5D%2C%5B108%2C231.383%2C296.042%2C240.967%5D%2C%5B107.701%2C220.424%2C297.687%2C230.008%5D%2C%5B108%2C209.465%2C503.997%2C219.049%5D%2C%5B107.701%2C198.507%2C504%2C208.091%5D%2C%5B108%2C187.548%2C274.027%2C197.132%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2210%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=10&#x26;annotation=S2U2ZZL4"><span style="background-color: #2ea8e580">â€œWe referred to Wei et al. (2023) and constructed an Adversarial (ADV) Set with shuffled options and paraphrased reference answers and evaluated the difference between original and ADV results. Results (Table 3) show a negligible performance drop (0.1% Ìƒ1.2%) for all models, indicating minimal likelihood of these models being trained on our dataset.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2210%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 10</a></span>)</span>\
**æˆ‘ä»¬å‚è€ƒäº†Weiç­‰äººï¼ˆ2023ï¼‰çš„ç ”ç©¶ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒ…å«é€‰é¡¹æ‰“ä¹±ä»¥åŠå‚è€ƒç­”æ¡ˆæ”¹å†™çš„å¯¹æŠ—ï¼ˆADVï¼‰é›†åˆï¼Œå¹¶è¯„ä¼°äº†åŸå§‹ç»“æœä¸ADVç»“æœä¹‹é—´çš„å·®å¼‚ã€‚ç»“æœï¼ˆè¡¨3ï¼‰æ˜¾ç¤ºï¼Œæ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½ä¸‹é™å¾®ä¹å…¶å¾®ï¼ˆ0.1%è‡³1.2%ï¼‰ï¼Œè¡¨æ˜è¿™äº›æ¨¡å‹è¢«è®­ç»ƒä½¿ç”¨æˆ‘ä»¬æ•°æ®é›†çš„å¯èƒ½æ€§æå°ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%223VIT9BEU%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%2210%22%2C%22position%22%3A%7B%22pageIndex%22%3A9%2C%22rects%22%3A%5B%5B107.671%2C59.329%2C492.815%2C68.913%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2210%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=10&#x26;annotation=3VIT9BEU"><span style="background-color: #2ea8e580">â€œ(1) The performance of proprietary models still surpasses that of open-source modelsâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2210%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 10</a></span>)</span>\
**ä¸“æœ‰æ¨¡å‹çš„æ€§èƒ½ä»ä¼˜äºå¼€æºæ¨¡å‹ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22ZJ2U3ALR%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%2211%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B407.297%2C438.231%2C503.997%2C447.815%5D%2C%5B108%2C427.272%2C470.256%2C436.856%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2211%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=11&#x26;annotation=ZJ2U3ALR"><span style="background-color: #2ea8e580">â€œIn comparison to the results on the multi-image set, the performance of proprietary models declinedâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2211%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 11</a></span>)</span>\
**ä¸å¤šå›¾åƒé›†ä¸Šçš„ç»“æœç›¸æ¯”ï¼Œä¸“æœ‰æ¨¡å‹çš„æ€§èƒ½æœ‰æ‰€ä¸‹é™ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22BQ3XHMME%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%2211%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B304.307%2C339.601%2C503.995%2C349.185%5D%2C%5B108%2C328.642%2C466.911%2C338.226%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2211%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=11&#x26;annotation=BQ3XHMME"><span style="background-color: #2ea8e580">â€œCompared to the results on the multi-image set, the performance of some open-source models with short contexts improvedâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2211%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 11</a></span>)</span>\
**ä¸å¤šå›¾åƒé›†ä¸Šçš„ç»“æœç›¸æ¯”ï¼ŒæŸäº›å…·æœ‰çŸ­ä¸Šä¸‹æ–‡çš„å¼€æºæ¨¡å‹çš„æ€§èƒ½æœ‰æ‰€æå‡ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22DD5F8LEV%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%2211%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B174.839%2C201.795%2C327.715%2C211.379%5D%2C%5B107.671%2C190.836%2C327.719%2C200.42%5D%2C%5B108%2C179.877%2C327.717%2C189.461%5D%2C%5B108%2C168.918%2C328.963%2C178.502%5D%2C%5B108%2C157.959%2C327.714%2C167.543%5D%2C%5B108%2C147%2C203.643%2C156.584%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2211%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=11&#x26;annotation=DD5F8LEV"><span style="background-color: #2ea8e580">â€œWe found that, aside from Task S-3 (Visual Relation Inference), tasks within the same category (either temporal multi-image or semantic multi-image) exhibited high correlation. Task S-3, being a challenging one, showed little variation in scores across models.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2211%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 11</a></span>)</span>\
**æˆ‘ä»¬å‘ç°ï¼Œé™¤äº†ä»»åŠ¡ S-3ï¼ˆè§†è§‰å…³ç³»æ¨ç†ï¼‰ä¹‹å¤–ï¼ŒåŒç±»åˆ«å†…çš„ä»»åŠ¡ï¼ˆæ— è®ºæ˜¯æ—¶é—´å¤šå›¾è¿˜æ˜¯è¯­ä¹‰å¤šå›¾ï¼‰è¡¨ç°å‡ºé«˜åº¦çš„ç›¸å…³æ€§ã€‚ä»»åŠ¡ S-3 ç”±äºå…¶éš¾åº¦è¾ƒå¤§ï¼Œåœ¨ä¸åŒæ¨¡å‹ä¹‹é—´çš„å¾—åˆ†å·®å¼‚è¾ƒå°ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%2258U2SSBX%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%2211%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B221.64%2C147%2C327.994%2C156.584%5D%2C%5B107.691%2C136.042%2C328.711%2C145.626%5D%2C%5B108%2C125.083%2C328.959%2C134.667%5D%2C%5B107.701%2C114.124%2C327.718%2C123.708%5D%2C%5B108%2C103.165%2C329.376%2C112.749%5D%2C%5B107.701%2C92.206%2C196.302%2C101.79%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2211%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=11&#x26;annotation=58U2SSBX"><span style="background-color: #2ea8e580">â€œWe also noted that Task T-3 (Visual Navigation and Spatial Localization) demonstrated lower correlation with other tasks, possibly due to its requirement of unique cognitive skills such as understanding the world from a firstperson perspective.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2211%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 11</a></span>)</span>\
**æˆ‘ä»¬è¿˜æ³¨æ„åˆ°ï¼Œä»»åŠ¡T-3ï¼ˆè§†è§‰å¯¼èˆªå’Œç©ºé—´å®šä½ï¼‰ä¸å…¶ä»–ä»»åŠ¡çš„ç›¸å…³æ€§è¾ƒä½ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºè¯¥ä»»åŠ¡éœ€è¦ç‹¬ç‰¹çš„è®¤çŸ¥æŠ€èƒ½ï¼Œä¾‹å¦‚ä»ç¬¬ä¸€äººç§°è§†è§’ç†è§£ä¸–ç•Œã€‚**

## <span style="color: rgb(190, 27, 65)">ğŸ’¡è®ºæ–‡çš„åˆ›æ–°ï¼š</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22R7UTGXL7%22%2C%22color%22%3A%22%23a28ae5%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B108.249%2C235.033%2C505.655%2C244.617%5D%2C%5B108%2C224.074%2C137.916%2C233.658%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=3&#x26;annotation=R7UTGXL7"><span style="background-color: #a28ae580">â€œMILEBENCH consists of two major components: Realistic Evaluation and Diagnostic Evaluationâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 3</a></span>)</span>\
**MILEBENCHç”±ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ç»„æˆï¼šç°å®è¯„ä¼°å’Œè¯Šæ–­è¯„ä¼°**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%2295T5LNLJ%22%2C%22color%22%3A%22%23a28ae5%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B107.691%2C123.338%2C505.249%2C132.922%5D%2C%5B108%2C112.379%2C347.627%2C121.963%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=3&#x26;annotation=95T5LNLJ"><span style="background-color: #a28ae580">â€œThe realistic evaluation is designed to assess an MLLMâ€™s ability to comprehend, integrate, and infer information in a multimodal long context.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 3</a></span>)</span>\
**å¤šæ¨¡æ€é•¿ä¸Šä¸‹æ–‡ä¸­çš„ç°å®è¯„ä¼°æ—¨åœ¨è¯„ä¼°å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMï¼‰çš„ç†è§£ã€æ•´åˆå’Œæ¨æ–­ä¿¡æ¯çš„èƒ½åŠ›ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22GZEHKQPX%22%2C%22color%22%3A%22%23a28ae5%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B354.09%2C112.379%2C503.997%2C121.963%5D%2C%5B108%2C101.42%2C457.805%2C111.004%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=3&#x26;annotation=GZEHKQPX"><span style="background-color: #a28ae580">â€œWe categorize the tasks into two main groups: Temporal Multi-Image tasks and Semantic Multi-Image tasks.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 3</a></span>)</span>\
**æˆ‘ä»¬å°†ä»»åŠ¡åˆ†ä¸ºä¸¤å¤§ç±»ï¼šæ—¶é—´å¤šå›¾ä»»åŠ¡å’Œè¯­ä¹‰å¤šå›¾ä»»åŠ¡ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22PVERT822%22%2C%22color%22%3A%22%23a28ae5%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B461.139%2C101.42%2C504.001%2C111.004%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=3&#x26;annotation=PVERT822"><span style="background-color: #a28ae580">â€œTemporalâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 3</a></span>)</span>\
**æ—¶é—´å¤šå›¾ä»»åŠ¡æµ‹è¯•MLLMåœ¨å¤šä¸ªæ—¶é—´ç›¸å…³å›¾åƒä¸­è¾¨åˆ«æ—¶é—´å…³ç³»çš„èƒ½åŠ›ï¼Œå¼ºè°ƒæ¨¡å‹åœ¨ç°å®åœºæ™¯ä¸­çš„é¢„æµ‹èƒ½åŠ›ã€‚å¦ä¸€æ–¹é¢ï¼Œè¯­ä¹‰å¤šå›¾ä»»åŠ¡åˆ™è€ƒéªŒMLLMå¤„ç†å¯èƒ½ä¸æ—¶é—´æ— å…³ä½†åœ¨è¯­ä¹‰ä¸Šäº’ç›¸å…³è”çš„å¤šä¸ªå›¾åƒçš„èƒ½åŠ›ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22UQJPXMLV%22%2C%22color%22%3A%22%23a28ae5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B192.753%2C670.642%2C504%2C680.226%5D%2C%5B107.502%2C659.683%2C505.247%2C669.267%5D%2C%5B107.582%2C648.724%2C504.201%2C658.308%5D%2C%5B107.611%2C636.13%2C503.996%2C647.705%5D%2C%5B108%2C625.171%2C504.004%2C634.755%5D%2C%5B108%2C614.213%2C505.747%2C623.797%5D%2C%5B107.611%2C603.254%2C504.002%2C612.838%5D%2C%5B108%2C592.295%2C493.274%2C601.879%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%227%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=7&#x26;annotation=UQJPXMLV"><span style="background-color: #a28ae580">â€œFor the open-source dataset comprised of the benchmark, we sample 10% of the data for manual verification. Our review team, composed entirely of authors, was assigned to scrutinize the precision of the sampled data, resulting in an Inter-annotator Agreement (IAA)5 of 95%, indicating a high level of consistency among reviewers. For the datasets we formulated independently, equivalent manual verification was carried out on the entirety of the dataset, yielding a similar IAA of 98%, thus ascertaining the data quality. Additionally, the error rate was found to be less than 1% for both datasets, affirming that these datasets maintain an exceptionally high quality and are virtually devoid of errors.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 7</a></span>)</span>\
**å¯¹äºåŒ…å«åŸºå‡†çš„å¼€æºæ•°æ®é›†ï¼Œæˆ‘ä»¬æŠ½å–äº†10%çš„æ•°æ®è¿›è¡Œäººå·¥æ ¸æŸ¥ã€‚æˆ‘ä»¬çš„å®¡æ ¸å›¢é˜Ÿç”±æ‰€æœ‰ä½œè€…ç»„æˆï¼Œè´Ÿè´£å®¡æŸ¥æŠ½æ ·æ•°æ®çš„å‡†ç¡®æ€§ï¼Œç»“æœè¡¨æ˜æ ‡æ³¨è€…é—´ä¸€è‡´æ€§åè®®ï¼ˆInter-annotator Agreementï¼ŒIAAï¼‰è¾¾åˆ°äº†95%ï¼Œè¡¨æ˜å®¡æ ¸äººå‘˜ä¹‹é—´å…·æœ‰è¾ƒé«˜çš„ä¸€è‡´æ€§ã€‚å¯¹äºæˆ‘ä»¬ç‹¬ç«‹åˆ¶å®šçš„æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œäº†åŒç­‰çš„äººå·¥æ ¸æŸ¥ï¼Œæ˜¾ç¤ºå‡ºç±»ä¼¼çš„IAAä¸º98%ï¼Œä»è€Œç¡®ä¿æ•°æ®è´¨é‡ã€‚æ­¤å¤–ï¼Œä¸¤ç»„æ•°æ®é›†çš„é”™è¯¯ç‡å‡ä½äº1%ï¼Œè¯æ˜è¿™äº›æ•°æ®é›†å…·æœ‰æé«˜çš„è´¨é‡ï¼Œå‡ ä¹æ²¡æœ‰é”™è¯¯ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22YCBTDUZK%22%2C%22color%22%3A%22%23a28ae5%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B404.417%2C376.097%2C504.003%2C385.681%5D%2C%5B108%2C365.138%2C503.998%2C374.722%5D%2C%5B108%2C354.179%2C503.997%2C363.763%5D%2C%5B108%2C343.22%2C503.997%2C352.804%5D%2C%5B108%2C332.261%2C329.193%2C341.845%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%227%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=7&#x26;annotation=YCBTDUZK"><span style="background-color: #a28ae580">â€œWhen the input length exceeds the maximum context length of the model, we keep the instruction, and truncate the interleaved image-text question from left so as to keep the question of a sample, as instruction and question are critical information and the importance of the last image is higher in many tasks, e.g. multimodal dialogue.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 7</a></span>)</span>\
**å½“è¾“å…¥é•¿åº¦è¶…è¿‡æ¨¡å‹çš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦æ—¶ï¼Œæˆ‘ä»¬ä¿ç•™æŒ‡ä»¤ï¼Œå¹¶ä»å·¦ä¾§æˆªæ–­äº¤é”™çš„å›¾æ–‡é—®é¢˜ï¼Œä»¥ä¿ç•™æ ·æœ¬çš„é—®é¢˜ï¼Œå› ä¸ºæŒ‡ä»¤å’Œé—®é¢˜æ˜¯å…³é”®ä¿¡æ¯ï¼Œå¹¶ä¸”åœ¨è®¸å¤šä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚å¤šæ¨¡æ€å¯¹è¯ï¼Œæœ€åä¸€å¼ å›¾åƒçš„é‡è¦æ€§æ›´é«˜ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22AJ9S7D4L%22%2C%22color%22%3A%22%23a28ae5%22%2C%22pageLabel%22%3A%2211%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B128.612%2C81.247%2C505.241%2C90.831%5D%2C%5B108%2C70.447%2C503.997%2C79.792%5D%2C%5B108%2C59.329%2C152.543%2C68.913%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2211%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=11&#x26;annotation=AJ9S7D4L"><span style="background-color: #a28ae580">â€œthe realistic evaluation of MILEBENCH encompasses a broad range of task types, offering a more comprehensive assessment in the context of multi-image long-context scenarios.â€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%2211%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 11</a></span>)</span>\
**MILEBENCHçš„ç°å®è¯„ä¼°æ¶µç›–äº†å¹¿æ³›çš„ä»»åŠ¡ç±»å‹ï¼Œåœ¨å¤šå›¾åƒé•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸­æä¾›äº†æ›´å…¨é¢çš„è¯„ä¼°ã€‚**

## <span style="color: rgb(190, 27, 65)">ğŸ“—ç”Ÿè¯è®°å½•ï¼š</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22RGS3LR5I%22%2C%22color%22%3A%22%23aaaaaa%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B352.877%2C208.126%2C400.861%2C217.71%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=1&#x26;annotation=RGS3LR5I"><span style="background-color: #aaaaaa80">â€œpioneeringâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 1</a></span>)</span>\
**pioneering è‹± \[ËŒpaÉªÉ™ËˆnÉªÉ™rÉªÅ‹] ç¾ \[ËŒpaÉªÉ™ËˆnÉªrÉªÅ‹] adj. é¦–åˆ›çš„ï¼Œå…ˆé©±çš„ï¼›æœ‰å¼€åˆ›è€…ç‰¹ç‚¹çš„ v. åšå…ˆé”‹ï¼Œå€¡å¯¼ï¼›å¼€è¾Ÿï¼ˆé“è·¯ï¼‰ï¼ˆpioneer çš„ç°åœ¨åˆ†è¯ï¼‰**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22FL2235TE%22%2C%22color%22%3A%22%23aaaaaa%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B194.839%2C186.208%2C238.648%2C195.792%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=1&#x26;annotation=FL2235TE"><span style="background-color: #aaaaaa80">â€œcomprisesâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 1</a></span>)</span>\
**comprises vï¼åŒ…å«ï¼ŒåŒ…æ‹¬ï¼šç”±æŸäº›éƒ¨åˆ†ã€å…ƒç´ æˆ–æˆå‘˜ç»„æˆã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22GIUM7EKL%22%2C%22color%22%3A%22%23aaaaaa%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B352.62%2C98.537%2C416.325%2C108.121%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=1&#x26;annotation=GIUM7EKL"><span style="background-color: #aaaaaa80">â€œintensificationâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 1</a></span>)</span>\
**intensification è‹± \[ÉªnËŒtensÉªfÉªËˆkeÉªÊƒ(É™)n] ç¾ \[ÉªnËŒtensÉªfÉªËˆkeÉªÊƒ(É™)n] n. å¼ºåŒ–ï¼›åŠ å‰§ï¼›æ¿€çƒˆåŒ–ï¼›å¢å¼ºæ˜æš—åº¦**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22MSXEL8R3%22%2C%22color%22%3A%22%23aaaaaa%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B131.07%2C235.381%2C187.164%2C244.965%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=2&#x26;annotation=MSXEL8R3"><span style="background-color: #aaaaaa80">â€œencapsulatesâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 2</a></span>)</span>\
**encapsulates vï¼ 1. æ¦‚æ‹¬ï¼Œæ€»ç»“ï¼šå°†æŸäº‹ç‰©çš„ä¸»è¦ç‰¹ç‚¹æˆ–è¦ç‚¹ç”¨ç®€æ´çš„æ–¹å¼è¡¨è¾¾å‡ºæ¥ã€‚ 2. å°è£…ï¼šå°†æŸç‰©åŒ…è£¹æˆ–å°é—­åœ¨å¦ä¸€ç‰©ä½“å†…ã€‚**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22EWZQGXFN%22%2C%22color%22%3A%22%23aaaaaa%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B402.468%2C235.381%2C444.143%2C244.965%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=2&#x26;annotation=EWZQGXFN"><span style="background-color: #aaaaaa80">â€œprevalentâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 2</a></span>)</span>\
**prevalent è‹± \[ËˆprevÉ™lÉ™nt] ç¾ \[ËˆprevÉ™lÉ™nt] adj. ç››è¡Œçš„ï¼Œæ™®éçš„**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22AX2HUQD4%22%2C%22color%22%3A%22%23aaaaaa%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B332.425%2C150.943%2C390.256%2C160.527%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=2&#x26;annotation=AX2HUQD4"><span style="background-color: #aaaaaa80">â€œmanner akinâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 2</a></span>)</span>\
**ç±»ä¼¼çš„æ–¹å¼**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22R682YQN6%22%2C%22color%22%3A%22%23aaaaaa%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B453.352%2C507.421%2C485.542%2C517.005%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=3&#x26;annotation=R682YQN6"><span style="background-color: #aaaaaa80">â€œnotableâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 3</a></span>)</span>\
**notable è‹± \[ËˆnÉ™ÊŠtÉ™b(É™)l] ç¾ \[ËˆnoÊŠtÉ™b(É™)l] adj. æ˜¾è¦çš„ï¼Œå€¼å¾—æ³¨æ„çš„ï¼›éå¸¸æˆåŠŸçš„ï¼Œä»¤äººå°Šæ•¬çš„ n. æ˜¾è¦äººç‰©ï¼Œåæµ \[ å¤æ•° notables æ¯”è¾ƒçº§ more notable æœ€é«˜çº§ most notable ]**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22MQQRQZA4%22%2C%22color%22%3A%22%23aaaaaa%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B305.062%2C317.595%2C336.88%2C327.179%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%224%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=4&#x26;annotation=MQQRQZA4"><span style="background-color: #aaaaaa80">â€œdiscernâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 4</a></span>)</span>\
**discern è‹± \[dÉªËˆsÉœËn] ç¾ \[dÉªËˆsÉœËrn] v. ï¼ˆè‰°éš¾åœ°æˆ–åŠªåŠ›åœ°ï¼‰çœ‹å‡ºï¼Œè§‰å¯Ÿå‡ºï¼›äº†è§£ï¼Œè®¤è¯† \[ ç¬¬ä¸‰äººç§°å•æ•° discerns ç°åœ¨åˆ†è¯ discerning è¿‡å»å¼ discerned è¿‡å»åˆ†è¯ discerned ]**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%22GNWYDWK9%22%2C%22color%22%3A%22%23aaaaaa%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B117.054%2C389.4%2C173.94%2C399.013%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%228%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=8&#x26;annotation=GNWYDWK9"><span style="background-color: #aaaaaa80">â€œtrails behindâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%228%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 8</a></span>)</span>\
**è½åäº**

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FDGHN9QHG%22%2C%22annotationKey%22%3A%225YUJ95AK%22%2C%22color%22%3A%22%23aaaaaa%22%2C%22pageLabel%22%3A%229%22%2C%22position%22%3A%7B%22pageIndex%22%3A8%2C%22rects%22%3A%5B%5B122.684%2C409.043%2C171.654%2C418.627%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%229%22%7D%7D" ztype="zhighlight"><a href="zotero://open/library/items/DGHN9QHG?page=9&#x26;annotation=5YUJ95AK"><span style="background-color: #aaaaaa80">â€œinvestigateâ€</span></a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F17270594%2Fitems%2FSW4R2BA2%22%5D%2C%22locator%22%3A%229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/SW4R2BA2">Song ç­‰, 2024, p. 9</a></span>)</span>\
**investigate è‹± \[ÉªnËˆvestÉªÉ¡eÉªt] ç¾ \[ÉªnËˆvestÉªÉ¡eÉªt] v. ä¾¦å¯Ÿï¼ˆæŸäº‹ï¼‰ï¼›è°ƒæŸ¥ï¼ˆæŸäººï¼‰ï¼›ç ”ç©¶ \[ ç¬¬ä¸‰äººç§°å•æ•° investigates ç°åœ¨åˆ†è¯ investigating è¿‡å»å¼ investigated è¿‡å»åˆ†è¯ investigated ]**

***
